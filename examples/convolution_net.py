"""
This example shows how to build a fully-functional text classification application with command-line support for
training and testing with a minimum of code.

The model used in the application is copied from imdb_cnn_lstm.py in the Keras examples folder.

Run "python convolution_net.py --help" to see the command line options. Notice that they are identical to what is
provided by the "mycroft" command line application except that the hyper-parameter arguments correspond to the model
being trained below.
"""

import mycroft.console
import mycroft.model
import mycroft.text


# Write your own model by extending mycroft.model.TextEmbeddingClassifier. All you need to do is override the
# constructor to get your model's hyper-parameter values.
class ConvolutionNetClassifier(mycroft.model.SequentialTextEmbeddingClassifier):
    # (It is not necessary make the default hyper-parameter values class values, but I do so here for clarity's sake.)
    DROPOUT = 0.25
    FILTERS = 64
    KERNEL_SIZE = 5
    POOL_SIZE = 4
    LSTM_OUTPUT_SIZE = 70
    LEARNING_RATE = 0.001
    LANGUAGE_MODEL = "en"

    # Mycroft creates command line options for every keyword argument in the constructor. Argument names, types, and
    # defaults are taken from these arguments. Additionally, the constructor takes a training value as its first
    # positional argument. This will be tuple of (training text, training label, label names). The label names are
    # required by the base class, and the other training data is available in case the model hyper-parameters depend on
    # it.
    #
    # For this model, if values for sequence length or vocabulary are not specified to the constructor, they will be
    # derived from the training data. Specifying None as their default constructor argument tells the command line to
    # not provide default values for these hyper-parameter options and pass in None if the options are not specified on
    # the command line. In this case, the custom_command_line_options function must specify a type for these arguments.
    # (See below.)
    #
    # All the model hyper-parameters have default values specified in the constructor that are used as the default
    # values for the command line options.
    def __init__(self, training,
                 sequence_length=None, vocabulary_size=None,
                 train_embeddings=mycroft.model.SequentialTextEmbeddingClassifier.TRAIN_EMBEDDINGS,
                 dropout=DROPOUT, filters=FILTERS, kernel_size=KERNEL_SIZE, pool_size=POOL_SIZE,
                 lstm_output_size=LSTM_OUTPUT_SIZE, language_model=LANGUAGE_MODEL, learning_rate=LEARNING_RATE):
        from keras.layers import Dropout, Conv1D, MaxPooling1D, LSTM, Dense
        from keras.models import Sequential
        from keras.optimizers import Adam

        # Get the label names from the training data. If the sequence length is not specified, use the largest number
        # of tokens in any of the text. If the vocabulary size is not specified, use the number of unique types in the
        # training text.
        label_names, sequence_length, vocabulary_size = self.parameters_from_training(sequence_length, vocabulary_size,
                                                                                      training, language_model)
        # The TextSequenceEmbedder object tokenizes the text and converts it into sequences of indexes into the
        # embedding matrix.
        embedder = mycroft.text.TextSequenceEmbedder(vocabulary_size, sequence_length, language_model)

        # What follows is identical to the code in the Keras example with two exceptions:
        model = Sequential()

        # 1. The embedding layer is generated by an embedding object via the embedding_layer() function.
        model.add(self.embedding_layer(embedder, sequence_length, train_embeddings, mask_zero=True, name="embedding"))

        model.add(Dropout(dropout))
        model.add(Conv1D(filters, kernel_size, padding="valid", activation="relu", strides=1))
        model.add(MaxPooling1D(pool_size=pool_size))
        model.add(LSTM(lstm_output_size))

        # 2. The final fully-connected layer has been modified to handle multiclass classification instead of just
        # binary.
        model.add(Dense(len(label_names), activation="softmax", name="softmax"))
        optimizer = Adam(lr=learning_rate)
        model.compile(optimizer=optimizer, loss="sparse_categorical_crossentropy", metrics=["accuracy"])

        # This passes a Keras model, a mycroft.text.Embedder, and the label names back to the parent constructor.
        super().__init__(model, embedder, label_names)

    # Derived classes may optionally supply a custom_command_line_options class method that returns a dictionary that
    # specifies additional keyword arguments to provide to the argparse.addArgument command. Here they are used to
    # provide additional formatting to the help text. If a class overrides this function it must combine the dictionary
    # it creates with any received from parent classes.
    @classmethod
    def custom_command_line_options(cls):
        return {**super().custom_command_line_options(), **{
            "dropout": {"help": "Dropout rate (default %0.2f)" % cls.DROPOUT},
            "filters": {"help": "Number of filters (default %d)" % cls.FILTERS},
            "kernel_size": {"help": "Size of kernel  (default %d)" % cls.KERNEL_SIZE, "metavar": "SIZE"},
            "pool_size": {"help": "Size of pooling layer (default %d)" % cls.POOL_SIZE, "metavar": "SIZE"},
            "lstm_output_size": {"help": "LSTM output size (default %d)" % cls.LSTM_OUTPUT_SIZE, "metavar": "SIZE"},
            "learning_rate": {"metavar": "RATE", "help": "learning rate (default %0.5f)" % cls.LEARNING_RATE},
            "language_model": {"help": "Language model (default %s)" % cls.LANGUAGE_MODEL, "metavar": "MODEL"}
        }}


if __name__ == "__main__":
    # The main function incorporates the custom model into Mycroft's command line framework.
    mycroft.console.main([(ConvolutionNetClassifier, "convnet", "Train a convolution network classifier")],
                         description="Convolution Network")
